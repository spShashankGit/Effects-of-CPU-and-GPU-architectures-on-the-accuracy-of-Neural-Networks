{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db70bdc6",
   "metadata": {},
   "source": [
    "# CIFAR 10 dataset - Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n  %reload_ext autotime\ntime: 299 µs (started: 2021-04-15 18:36:49 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "662f52f4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 238 µs (started: 2021-04-15 18:36:50 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4daea7bc",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 311 µs (started: 2021-04-15 18:36:51 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ef06e55",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 300 µs (started: 2021-04-15 18:36:51 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000,3,32,32)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8567005a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 366 µs (started: 2021-04-15 18:36:52 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe9991da",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 406 µs (started: 2021-04-15 18:36:52 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'CIFAR-10-DS/cifar-10-batches-py/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    x_train = X_train.astype('float32')\n",
    "    x_test = X_test.astype('float32')\n",
    "\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    #return X_train, y_train, X_test, y_test\n",
    "    #return x_train, y_train, X_val, y_val, x_test, y_test \n",
    "\n",
    "    return x_train, y_train, x_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db5bfd60",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train  <class 'numpy.ndarray'> (49000, 3, 32, 32)\ny_train (49000,)\nx_test (10000, 3, 32, 32)\ny_test (10000,)\ntime: 627 ms (started: 2021-04-15 18:36:53 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the above function to get our data.\n",
    "x_train, y_train, x_test, y_test = get_CIFAR10_data()\n",
    "\n",
    "print('x_train ', type(x_train), x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Create batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 352 µs (started: 2021-04-15 18:36:57 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def createBatches(data,batch_size_required):\n",
    "    batch_size = int(len(data)/batch_size_required)\n",
    "    res=[]\n",
    "    print('Data ',len(data))\n",
    "    for i in range (batch_size):\n",
    "        batched_data = data[i*batch_size_required:i*batch_size_required+batch_size_required]\n",
    "        res.append(batched_data)\n",
    "        #print('Check here', len(batched_data))\n",
    "    res = np.asarray(res)\n",
    "    print('Res ',len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data  49000\n",
      "Res  765\n",
      "Data  49000\n",
      "Res  765\n",
      "Data  10000\n",
      "Res  156\n",
      "Data  10000\n",
      "Res  156\n",
      "time: 322 ms (started: 2021-04-15 18:37:00 +02:00)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "x_train = createBatches(x_train,64)\n",
    "y_train = createBatches(y_train,64)\n",
    "\n",
    "x_test = createBatches(x_test,64)\n",
    "y_test = createBatches(y_test,64)"
   ]
  },
  {
   "source": [
    "## Convert npArray to tensor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X tensor  <class 'torch.Tensor'>\ntime: 2.62 ms (started: 2021-04-15 18:37:38 +02:00)\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.as_tensor(x_train)\n",
    "y_train_tensor = torch.as_tensor(y_train)\n",
    "\n",
    "x_test_tensor = torch.as_tensor(x_test)\n",
    "y_test_tensor = torch.as_tensor(y_test)\n",
    "\n",
    "print('X tensor ', type(x_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "\n",
    "\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=bth_size,shuffle=True, num_workers=2)\n",
    "\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=bth_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "source": [
    "### Preview CIFAR-10 dataset images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Invalid shape (32, 32, 3, 64) for image data",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-83035762c451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# print labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#print(' '.join('%5s' % classes[labels[j]] for j in range(32)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-83035762c451>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2872\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2873\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5587\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5589\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5590\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pytorch_env/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    707\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    708\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 709\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    710\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (32, 32, 3, 64) for image data"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(img.shape)\n",
    "    plt.imshow(np.transpose(img))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "#dataiter = iter(trainloader)\n",
    "#print(dataiter)\n",
    "#images, labels = dataiter.next()\n",
    "images = x_train_tensor\n",
    "labels = y_train_tensor\n",
    "\n",
    "# show images\n",
    "imshow(images[50])\n",
    "# print labels\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(32)))"
   ]
  },
  {
   "source": [
    "### Setting up the layers of Convolutional neural network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 411 µs (started: 2021-04-15 18:38:03 +02:00)\n"
     ]
    }
   ],
   "source": [
    "in_size = 3                 # number of channel in the input image\n",
    " \n",
    "hid1_size = 64              # no of output channel from first CNN layer\n",
    "\n",
    "hid2_size = 128             # no of output channel from second CNN layer\n",
    "\n",
    "hid3_size = 256             # no of output channel from third CNN layer\n",
    "\n",
    "hid4_size = 512             # no of output channel from forth CNN layer\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "out_size = len(classes)     # no of categories in the dataset\n",
    "\n",
    "k_conv_size = 3             # 3x3 convolutional kernel\n",
    "\n",
    "conv_stride = 1             # conv stride 1\n",
    "\n",
    "conv_pad = 1                # conv padding 1\n",
    "\n",
    "maxpool_kernel = 2          # maxpool layer kernel size 2 x 2\n",
    "\n",
    "maxpool_stride = 2          # maxpool layer stride 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 43.2 ms (started: 2021-04-15 18:38:03 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class VGG_11(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VGG_11,self).__init__()\n",
    "        \n",
    "        self.convLayer = nn.Sequential(\n",
    "            nn.Conv2d(in_size, hid1_size, k_conv_size, stride=conv_stride, padding=conv_pad),    # conv layer\n",
    "            nn.BatchNorm2d(hid1_size),\n",
    "            #nn.LocalResponseNorm(64),\n",
    "            nn.ReLU(),                              # Activation layer\n",
    "            nn.MaxPool2d(kernel_size=maxpool_kernel,stride=maxpool_stride),\n",
    "            \n",
    "            nn.Conv2d(hid1_size,hid2_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=maxpool_kernel,stride=maxpool_stride),\n",
    "            \n",
    "            nn.Conv2d(hid2_size,hid3_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid3_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(hid3_size,hid3_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid3_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=maxpool_kernel,stride=maxpool_stride),\n",
    "            \n",
    "            nn.Conv2d(hid3_size,hid4_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid4_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(hid4_size,hid4_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid4_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=maxpool_kernel,stride=maxpool_stride),\n",
    "            \n",
    "            nn.Conv2d(hid4_size,hid4_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid4_size),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(hid4_size,hid4_size,k_conv_size, stride=conv_stride, padding=conv_pad),\n",
    "            nn.BatchNorm2d(hid4_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=maxpool_kernel,stride=maxpool_stride), \n",
    "            \n",
    "            #nn.Flatten(0,-1),\n",
    "            \n",
    "            #nn.Linear(512*bth_size, out_size)\n",
    "            \n",
    "        )\n",
    "        \n",
    "     \n",
    "        self.fullyConnLayer = nn.Sequential(\n",
    "            nn.Linear(512, out_size),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "            \n",
    "        \n",
    "    def forward(self,x):\n",
    "            out = self.convLayer(x)\n",
    "\n",
    "            out = out.reshape(out.size(0), -1)\n",
    "            \n",
    "            out = self.fullyConnLayer(out)\n",
    "            \n",
    "            return out \n",
    "        \n",
    "vgg_11 = VGG_11()"
   ]
  },
  {
   "source": [
    "## Define a Loss function and optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 540 µs (started: 2021-04-15 18:38:05 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(vgg_11.parameters())"
   ]
  },
  {
   "source": [
    "## Train the network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,   200] loss: 2.287\n",
      "[1,   400] loss: 1.696\n",
      "[1,   600] loss: 1.451\n",
      "Finished Training\n",
      "time: 12min 55s (started: 2021-04-15 18:38:07 +02:00)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(x_train_tensor, 0):\n",
    "        #inputs, labels = data\n",
    "        \n",
    "        #images = data\n",
    "        #print(data.shape)\n",
    "        inputs = data\n",
    "        labels = y_train_tensor[i]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg_11(inputs)\n",
    "        \n",
    "        #print(type(outputs))\n",
    "        #print(type(labels))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # print statistics        \n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "source": [
    "## Test the network on the test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = vgg_11(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(32)))"
   ]
  },
  {
   "source": [
    "### Accuracy on whole test-dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 56 %\ntime: 24.1 s (started: 2021-04-15 18:51:44 +02:00)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(x_test_tensor, 0):\n",
    "        #images, labels = data\n",
    "        #print('test ', len(data))\n",
    "        images = data\n",
    "        labels = y_test_tensor[i]\n",
    "\n",
    "        outputs = vgg_11(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "source": [
    "### Which classes perform well and which classes did not?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of plane : 65 %\nAccuracy of   car : 78 %\nAccuracy of  bird : 15 %\nAccuracy of   cat : 54 %\nAccuracy of  deer : 27 %\nAccuracy of   dog : 20 %\nAccuracy of  frog : 73 %\nAccuracy of horse : 46 %\nAccuracy of  ship : 80 %\nAccuracy of truck : 60 %\ntime: 23.7 s (started: 2021-04-15 18:52:43 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(x_test_tensor, 0):\n",
    "        #images, labels = data\n",
    "        images = data\n",
    "        labels = y_test_tensor[i]\n",
    "\n",
    "        outputs = vgg_11(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [np.random.randn(3, 32,32) for _ in range(128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.stack(arrays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 3, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = np.stack(test,axis=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(np.split(test, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64, 2, 3, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "no_of_batches = abs(len(test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(data,batch_size_required):\n",
    "    batch_size = int(len(data)/batch_size_required)\n",
    "    res=[]\n",
    "    print(len(data))\n",
    "    for i in range (batch_size):\n",
    "        batched_data = data[i*batch_size_required:i*batch_size_required+batch_size_required]\n",
    "        res.append(batched_data)\n",
    "        print('Check here', len(batched_data))\n",
    "    res = np.asarray(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 3, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "128\nCheck here 64\nCheck here 64\n"
     ]
    }
   ],
   "source": [
    "b_d = createBatches(test,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "len(b_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "resttt = np.asarray(b_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64, 3, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "resttt[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}